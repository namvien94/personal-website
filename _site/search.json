[
  {
    "objectID": "coursework.html",
    "href": "coursework.html",
    "title": "Coursework",
    "section": "",
    "text": "Term\nCourses\nSyllabus\n\n\n\n\nFall 2023\nMATH 115A - Linear Algebra\nView Syllabus\n\n\nFall 2023\nDH 101 - Introduction to Digital Humanities\nView Syllabus\n\n\nWinter 2024\nMATH 106 - History of Mathematics\nView Syllabus\n\n\nWinter 2024\nSTATS 20 - Introduction to Statistical Programming with R\nView Syllabus\n\n\nWinter 2024\nSTATS 100A - Introduction to Probability\nView Syllabus\n\n\nSpring 2024\nSTATS 101A - Introduction to Data Analysis and Regression\nView Syllabus\n\n\nSpring 2024\nMATH 170S - Introduction to Probability and Statistics 2: Statistics\nView Syllabus\n\n\nSummer 2024\nSTATS 101B - Introduction to Design and Analysis of Experiment\nView Syllabus\n\n\nSummer 2024\nSTATS 102A - Introduction to Computational Statistics with R\nView Syllabus\n\n\nSummer 2024\nSTATS 102B - Introduction to Computation and Optimization for Statistics\nView Syllabus\n\n\nFall 2024\nSTATS 101C - Introduction to Statistical Models and Data Mining\nView Syllabus\n\n\nFall 2024\nSTATS 102C - Introduction to Monte Carlo Methods\nView Syllabus\n\n\nFall 2024\nSTATS 140XP - Practice of Statistical Consulting\nView Syllabus\n\n\nFall 2024\nDH M121 - Race, Gender, and Data\nView Syllabus\n\n\nWinter 2025\nDH 131 - Digital Mapping and Critical Geographic Information Systems\nView Syllabus\n\n\nWinter 2025\nSTATS 141XP - Statistics Consulting\nView Syllabus\n\n\nSpring 2025\nDH 187 - Capstone Seminar: (Re)Defining LA\nView Syllabus\n\n\nSpring 2025\nSTATS 100C - Linear Models\nView Syllabus"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Nam Vien",
    "section": "",
    "text": "üîä Start\nNam Vien is a UCLA Statistics & Data Science graduate who specializes in uncovering user needs, synthesizing insights, and shaping early product concepts. With experience in ecosystem analysis, prototyping, and cross-functional collaboration, he is driven to build intuitive, scalable experiences across social and creator-centric platforms."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Nam Vien",
    "section": "Education",
    "text": "Education\nUniversity of California, Los Angeles\nBachelor of Science in Statistics and Data Science\nMinor in Digital Humanities\n\nCornell University, New York\nE-certificate in Machine Learning Foundations"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Nam Vien",
    "section": "Experience",
    "text": "Experience\nEvaluation Assistant | UCLA Undergraduate Admission | February 2024 - September 2025\nAI/ML Studio Fellow | Saciva |\nAugust 2024 - December 2024"
  },
  {
    "objectID": "index.html#leadership",
    "href": "index.html#leadership",
    "title": "Nam Vien",
    "section": "Leadership",
    "text": "Leadership\nBreak Through Tech AI Fellow | Cornell University x UCLA\nCertificate of Completion\n\nData Justice Scholar\nUCLA Center for Community Engagement\n\nDEEPenn STEM Scholar | University of Pennsylvania"
  },
  {
    "objectID": "projects/Project 1/Project 1.html",
    "href": "projects/Project 1/Project 1.html",
    "title": "Project 1 - Saciva",
    "section": "",
    "text": "Introduction: This project aims to create an intuitive clustering-based platform to help international students in the U.S. find suitable housing, roommates, and local connections. By analyzing geographic data and integrating cost of living, safety, and climate profiles, the goal is to replace traditional filters with a machine-learning approach that ensures broader, more efficient connections.\n\nProcess\n\nData Understanding and Preparation:\n\nMerged multiple datasets: geographic coordinates, cost of living, income, and campus safety metrics.\nConducted exploratory data analysis (EDA) to clean, visualize, and understand data patterns.\nCalculated seasonal climate metrics and normalized cost indices for accurate comparisons.\n\nClustering and Modeling:\n\nApplied clustering algorithms (DBSCAN, Mean Shift, Agglomerative) to group universities based on proximity.\nOptimized clustering parameters using metrics like Silhouette Score for model evaluation.\nSelected DBSCAN as the final clustering model due to its highest Silhouette Score (0.868).\n\nProfiling and Visualization:\n\nCreated detailed cluster profiles, analyzing cost of living, safety scores, and climate characteristics.\nGenerated interactive maps and data visualizations (e.g., heatmaps and boxplots) to enhance understanding.\n\n\n\nOutcome\n\nSuccessfully created 294 meaningful clusters with distinct profiles based on geographic and socioeconomic factors.\nDemonstrated the feasibility of clustering as a robust alternative to traditional filtering methods.\nDelivered a scalable framework for streamlining housing and networking for international students, offering insights into cost, climate, and safety within commuting zones."
  },
  {
    "objectID": "projects/Project 1/Project 1.html#summary",
    "href": "projects/Project 1/Project 1.html#summary",
    "title": "Project 1 - Saciva",
    "section": "",
    "text": "Introduction: This project aims to create an intuitive clustering-based platform to help international students in the U.S. find suitable housing, roommates, and local connections. By analyzing geographic data and integrating cost of living, safety, and climate profiles, the goal is to replace traditional filters with a machine-learning approach that ensures broader, more efficient connections.\n\nProcess\n\nData Understanding and Preparation:\n\nMerged multiple datasets: geographic coordinates, cost of living, income, and campus safety metrics.\nConducted exploratory data analysis (EDA) to clean, visualize, and understand data patterns.\nCalculated seasonal climate metrics and normalized cost indices for accurate comparisons.\n\nClustering and Modeling:\n\nApplied clustering algorithms (DBSCAN, Mean Shift, Agglomerative) to group universities based on proximity.\nOptimized clustering parameters using metrics like Silhouette Score for model evaluation.\nSelected DBSCAN as the final clustering model due to its highest Silhouette Score (0.868).\n\nProfiling and Visualization:\n\nCreated detailed cluster profiles, analyzing cost of living, safety scores, and climate characteristics.\nGenerated interactive maps and data visualizations (e.g., heatmaps and boxplots) to enhance understanding.\n\n\n\nOutcome\n\nSuccessfully created 294 meaningful clusters with distinct profiles based on geographic and socioeconomic factors.\nDemonstrated the feasibility of clustering as a robust alternative to traditional filtering methods.\nDelivered a scalable framework for streamlining housing and networking for international students, offering insights into cost, climate, and safety within commuting zones."
  },
  {
    "objectID": "projects/Project 1/Project 1.html#project-outputs",
    "href": "projects/Project 1/Project 1.html#project-outputs",
    "title": "Project 1 - Saciva",
    "section": "Project Outputs",
    "text": "Project Outputs"
  },
  {
    "objectID": "projects/Project 1/Project 1.html#supporting-documents",
    "href": "projects/Project 1/Project 1.html#supporting-documents",
    "title": "Project 1 - Saciva",
    "section": "Supporting Documents",
    "text": "Supporting Documents\nGroup Presentation\nDownload or view the PDF\n\n\nThis project was part of the Fall 2024 AI Studio, led by SACIVA CEO Abhi Medikonduri,\nguided by TA Dominic Diaz at UCLA Break Through Tech AI program."
  },
  {
    "objectID": "projects/Project 5/Project 5.html",
    "href": "projects/Project 5/Project 5.html",
    "title": "Project 5 - Machine Learning Models",
    "section": "",
    "text": "This assignment involves reproducing key plots and results to analyze the bias-variance tradeoff, function class comparisons, and KNN testing performance."
  },
  {
    "objectID": "projects/Project 5/Project 5.html#assignment-1",
    "href": "projects/Project 5/Project 5.html#assignment-1",
    "title": "Project 5 - Machine Learning Models",
    "section": "",
    "text": "This assignment involves reproducing key plots and results to analyze the bias-variance tradeoff, function class comparisons, and KNN testing performance."
  },
  {
    "objectID": "projects/Project 5/Project 5.html#assignment-2",
    "href": "projects/Project 5/Project 5.html#assignment-2",
    "title": "Project 5 - Machine Learning Models",
    "section": "Assignment 2",
    "text": "Assignment 2\nThis assignment is about plotting the decision boundaries of LDA, QDA, and Logistic Loss minimization on BankNote_Authentication.csv\nThe BankNote_Authentication.csv contains 5 variables: (1) variance (2) skewness (3) curtosis (4) entropy (5) class\nThe first four variables are features of banknote and the last variable is the class indicating whether this banknote is real or not."
  },
  {
    "objectID": "projects/Project 5/Project 5.html#assignment-3",
    "href": "projects/Project 5/Project 5.html#assignment-3",
    "title": "Project 5 - Machine Learning Models",
    "section": "Assignment 3",
    "text": "Assignment 3\nThis assignment focuses on applying and comparing supervised learning techniques‚Äîdecision trees, random forests, and boosting‚Äîon the Banknote dataset. The objective is to evaluate and contrast their predictive performance based on testing errors after training models with specific hyperparameters."
  },
  {
    "objectID": "projects/Project 5/Project 5.html#assignment-4",
    "href": "projects/Project 5/Project 5.html#assignment-4",
    "title": "Project 5 - Machine Learning Models",
    "section": "Assignment 4",
    "text": "Assignment 4\nIn this dataset, there are 6 predictors X_1‚Ä¶,X_6 and 1 response variable.\nThere are 3 predictors that should not be included in the regression model.\nApply LASSO to figure out those variables.\n\nFind the attached csv file: DF_LASSO"
  },
  {
    "objectID": "projects/Project 5/Project 5.html#assignment-5",
    "href": "projects/Project 5/Project 5.html#assignment-5",
    "title": "Project 5 - Machine Learning Models",
    "section": "Assignment 5",
    "text": "Assignment 5\nThis assignment explores the application of linear and kernel Support Vector Machine (SVM) models on a dataset, focusing on their performance and visualization. By comparing testing accuracies and plotting decision boundaries, the assignment highlights the impact of model selection and kernel usage in classification tasks.\nFind the attached csv file: Data\n\n\n\n\nThese assignments were part of Professor Shirong Xu‚Äôs Stats 101C F24, guided by TA Zhi Zhang,\nat UCLA Department of Statistics and Data Science."
  },
  {
    "objectID": "projects/Project 3/Project 3.html",
    "href": "projects/Project 3/Project 3.html",
    "title": "Project 3 - Unhoused Individuals in Los Angeles County",
    "section": "",
    "text": "Introduction: This project investigates the demographic and geographic trends of homelessness in Los Angeles County, emphasizing service disparities and influencing factors.\nProcess:\n\nData Collection:\n\nUtilized datasets from the California Interagency Council on Homelessness (Cal ICH) and Los Angeles Homeless Services Authority (LAHSA).\nMerged datasets to analyze trends by race, gender, and geography.\n\nData Cleaning & Aggregation:\n\nProcessed raw data for consistency, removed incomplete records, and combined multiple sources.\n\nAnalysis & Visualization:\n\nConducted geospatial analysis using Folium for mapping homelessness distribution.\nCreated visualizations like bar charts and demographic distribution graphs.\n\nCollaboration:\n\nWorked in a team, leveraging individual strengths and discussing findings in the context of policy impacts.\n\n\nOutcome:\n\nHighlighted downtown Los Angeles as the area with the highest homelessness count.\n\nRevealed significant disparities in homelessness rates across racial and gender demographics.\n\nDemonstrated the effectiveness of visualization tools in identifying trends and guiding resource allocation policies."
  },
  {
    "objectID": "projects/Project 3/Project 3.html#summary",
    "href": "projects/Project 3/Project 3.html#summary",
    "title": "Project 3 - Unhoused Individuals in Los Angeles County",
    "section": "",
    "text": "Introduction: This project investigates the demographic and geographic trends of homelessness in Los Angeles County, emphasizing service disparities and influencing factors.\nProcess:\n\nData Collection:\n\nUtilized datasets from the California Interagency Council on Homelessness (Cal ICH) and Los Angeles Homeless Services Authority (LAHSA).\nMerged datasets to analyze trends by race, gender, and geography.\n\nData Cleaning & Aggregation:\n\nProcessed raw data for consistency, removed incomplete records, and combined multiple sources.\n\nAnalysis & Visualization:\n\nConducted geospatial analysis using Folium for mapping homelessness distribution.\nCreated visualizations like bar charts and demographic distribution graphs.\n\nCollaboration:\n\nWorked in a team, leveraging individual strengths and discussing findings in the context of policy impacts.\n\n\nOutcome:\n\nHighlighted downtown Los Angeles as the area with the highest homelessness count.\n\nRevealed significant disparities in homelessness rates across racial and gender demographics.\n\nDemonstrated the effectiveness of visualization tools in identifying trends and guiding resource allocation policies."
  },
  {
    "objectID": "projects/Project 3/Project 3.html#project-outputs",
    "href": "projects/Project 3/Project 3.html#project-outputs",
    "title": "Project 3 - Unhoused Individuals in Los Angeles County",
    "section": "Project Outputs",
    "text": "Project Outputs"
  },
  {
    "objectID": "projects/Project 3/Project 3.html#supporting-documents",
    "href": "projects/Project 3/Project 3.html#supporting-documents",
    "title": "Project 3 - Unhoused Individuals in Los Angeles County",
    "section": "Supporting Documents",
    "text": "Supporting Documents\nDownload or view the PDF\n\n\nThis project was part of Dr.¬†Munia Bhaumik‚Äôs DH M121 F24 - Race, Gender, and Data: Whose Lives Count?\nat UCLA Digital Humanities Department."
  },
  {
    "objectID": "projects/Project 4/Project 4.html",
    "href": "projects/Project 4/Project 4.html",
    "title": "Project 4 - Aloha Airbnb",
    "section": "",
    "text": "The Aloha Airbnb project, developed by UCLA‚Äôs Digital Humanities 101 students in Fall 2023, examines the impact of short-term rentals (STRs) on Hawaiian tourist destinations, focusing on Lahaina and the Primary Urban Center (PUC) in Oahu. It explores both the economic benefits, such as increased income for hosts, and challenges like housing shortages and neighborhood transformations.\n\nTools and Methodologies Used\nThe project employed a range of digital tools and methodologies to analyze and present data effectively:\n\nData Collection and Analysis:\n\nInside Airbnb: Utilized as the primary data source, providing comprehensive information on Airbnb listings in the targeted Hawaiian regions.\nGoogle Sheets: Served as the platform for organizing and analyzing data, enabling collaborative examination of Airbnb‚Äôs impact on local housing markets.\nR: Used for data cleaning, statistical analysis, and generating insights. These tools were instrumental in processing large datasets and performing advanced analyses.\n\nData Visualization:\n\nTableau: Employed to create interactive visualizations, facilitating a deeper understanding of data patterns and trends related to STRs.\nPython: Used to create custom visualizations, supporting deeper exploration of trends and comparisons.\n\nWeb Development:\n\nWordPress: Used as the content management system (CMS) to design and structure the project website, allowing for dynamic content presentation and user engagement.\n\nMapping:\n\nGoogle Maps: Integrated to display the geographical distribution of Airbnb listings, providing spatial context to the data.\n\nCollaboration:\n\nSlack: Utilized for team communication, ensuring efficient collaboration among project members.\nGoogle Drive: Served as the repository for shared documents and resources, streamlining the workflow.\n\n\nThese tools collectively enabled the team to conduct a thorough analysis of STRs‚Äô effects on housing and communities in Hawaii, presenting findings in an accessible and informative manner.\n\n\nMeasurable Outcomes\nThe project achieved several quantifiable results:\n\nData-Driven Insights: Identified that 89.81% of Airbnb listings in Lahaina are entire homes or apartments, highlighting the significant presence of STRs in the housing market.\nAudience Engagement: The website attracted a substantial number of visitors, with interactive elements such as maps and timelines receiving high engagement rates, indicating effective dissemination of information.\nPolicy Implications: The analysis provided valuable data for policymakers, contributing to informed discussions on regulating STRs to balance economic benefits with community needs.\n\n\n\nQuestions This Project Can Answer\nThe Aloha Airbnb project addresses several critical questions:\n\nEconomic Impact: How do STRs affect local economies in Hawaiian tourist destinations?\nHousing Market Dynamics: What influence do STRs have on housing availability and affordability for local residents?\nCommunity Effects: In what ways do STRs alter neighborhood dynamics and the social fabric of communities?\nRegulatory Considerations: What are the potential benefits and drawbacks of implementing stricter regulations on STRs?\n\n\n\nPersonal Learning and Skill Development\nEngaging in this project facilitated significant personal and professional growth:\n\nData Analysis Proficiency: Enhanced ability to collect, organize, and interpret complex datasets, leading to more informed conclusions.\nTechnical Skills: Gained hands-on experience with tools like Tableau and WordPress, expanding technical capabilities in data visualization and web development.\nCollaborative Experience: Developed teamwork skills through coordinated efforts using platforms like Slack and Google Drive, emphasizing the importance of communication and cooperation.\nCritical Thinking: Refined the ability to critically assess the multifaceted impacts of STRs, considering economic, social, and policy perspectives.\n\n\n\n\nThis project was part of Professor Wendy Kurtz‚Äôs DH101 F23, guided by TA Nick Schwieterman\nat UCLA Digital Humanities Department."
  },
  {
    "objectID": "projects/Project 2/Project 2.html",
    "href": "projects/Project 2/Project 2.html",
    "title": "Project 2 - Uber Fare Prediction",
    "section": "",
    "text": "Introduction: This project aimed to predict Uber ride fare amounts based on trip and passenger data. The goal was to develop a machine-learning model capable of accurately estimating fare amounts using various features derived from the dataset. The project involved data exploration, cleaning, feature engineering, model training, and evaluation.\nProcess:\n\nData Exploration and Cleaning:\n\nImported and explored the dataset to understand its structure and content.\nIdentified and handled missing values and removed unrealistic records, focusing on trips within New York City.\n\nFeature Engineering:\n\nExtracted relevant features such as trip distance using the Haversine formula and time-based attributes like day, month, and hour.\nEncoded categorical variables and removed unnecessary columns for streamlined model training.\n\nModeling and Evaluation:\n\nEvaluated multiple regression models, including Linear Regression, Lasso, Ridge, Decision Tree, Random Forest, Gradient Boosting, XGBoost, and LightGBM.\nAssessed model performance using Root Mean Squared Error (RMSE) on the test dataset.\nSelected LightGBM as the best-performing model with the lowest RMSE of 3.75.\n\nPrediction:\n\nUsed the best-performing model to make fare predictions on the test dataset.\nSaved the predictions to a CSV file for review.\n\nVisualization:\n\nCreated a heatmap of pickup locations to visualize trip density across New York City.\n\n\nOutcome:\n\nSuccessfully developed and evaluated multiple machine learning models.\nIdentified LightGBM as the optimal model for fare prediction.\nDelivered a cleaned dataset, predictive model, and visualization outputs for further insights."
  },
  {
    "objectID": "projects/Project 2/Project 2.html#summary",
    "href": "projects/Project 2/Project 2.html#summary",
    "title": "Project 2 - Uber Fare Prediction",
    "section": "",
    "text": "Introduction: This project aimed to predict Uber ride fare amounts based on trip and passenger data. The goal was to develop a machine-learning model capable of accurately estimating fare amounts using various features derived from the dataset. The project involved data exploration, cleaning, feature engineering, model training, and evaluation.\nProcess:\n\nData Exploration and Cleaning:\n\nImported and explored the dataset to understand its structure and content.\nIdentified and handled missing values and removed unrealistic records, focusing on trips within New York City.\n\nFeature Engineering:\n\nExtracted relevant features such as trip distance using the Haversine formula and time-based attributes like day, month, and hour.\nEncoded categorical variables and removed unnecessary columns for streamlined model training.\n\nModeling and Evaluation:\n\nEvaluated multiple regression models, including Linear Regression, Lasso, Ridge, Decision Tree, Random Forest, Gradient Boosting, XGBoost, and LightGBM.\nAssessed model performance using Root Mean Squared Error (RMSE) on the test dataset.\nSelected LightGBM as the best-performing model with the lowest RMSE of 3.75.\n\nPrediction:\n\nUsed the best-performing model to make fare predictions on the test dataset.\nSaved the predictions to a CSV file for review.\n\nVisualization:\n\nCreated a heatmap of pickup locations to visualize trip density across New York City.\n\n\nOutcome:\n\nSuccessfully developed and evaluated multiple machine learning models.\nIdentified LightGBM as the optimal model for fare prediction.\nDelivered a cleaned dataset, predictive model, and visualization outputs for further insights."
  },
  {
    "objectID": "projects/Project 2/Project 2.html#project-outputs",
    "href": "projects/Project 2/Project 2.html#project-outputs",
    "title": "Project 2 - Uber Fare Prediction",
    "section": "Project Outputs",
    "text": "Project Outputs"
  },
  {
    "objectID": "projects/Project 2/Project 2.html#supporting-documents",
    "href": "projects/Project 2/Project 2.html#supporting-documents",
    "title": "Project 2 - Uber Fare Prediction",
    "section": "Supporting Documents",
    "text": "Supporting Documents\nProject Guidelines\nDownload or view the PDF\n\n\nThis project was part of Professor Vivian Lew‚Äôs Stats 101A S24, guided by TA Jialiang Geng,\nat UCLA Department of Statistics and Data Science."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "Project thumbnails sourced from Google Images; credit to the original creators.\n\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nProject 1 - Saciva\n\n\n\nGroup\n\n\nClustering\n\n\nNetworking\n\n\n\nThis project involves clustering U.S. universities to assist international students in networking and housing.\n\n\n\nNam Vien\n\n\nDec 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProject 2 - Uber Fare Prediction\n\n\n\nIndividual\n\n\nMachine Learning\n\n\nRegression\n\n\n\nThis project applies machine learning methods to predict Uber fares.\n\n\n\nNam Vien\n\n\nDec 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProject 3 - Unhoused Individuals in Los Angeles County\n\n\n\nGroup\n\n\nHomelessness\n\n\nSocial Impact\n\n\n\nThis project analyzes homelessness trends across Los Angeles neighborhoods (2017-2022), focusing on disparities by demographics.\n\n\n\nNam Vien\n\n\nDec 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProject 4 - Aloha Airbnb\n\n\n\nGroup\n\n\nGeographic Analysis\n\n\nWeb Development\n\n\n\nThis project examines the socio-economic impact of short-term rentals in Hawaii using data visualization, statistical analysis, and digital tools.\n\n\n\nNam Vien\n\n\nDec 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProject 5 - Machine Learning Models\n\n\n\nData Mining\n\n\nSupervised Learning\n\n\nClassification Models\n\n\n\nThis project explores advanced statistical techniques to analyze decision boundaries in datasets with multiple features, focusing on their practical applications.\n\n\n\nNam Vien\n\n\nDec 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProject 6 - Surveillance & Equity\n\n\n\nGroup\n\n\nSurveillance Studies\n\n\nDigital Mapping\n\n\n\nThis project explores how facial recognition technology intersects with racial diversity and spatial inequality in American cities through digital mapping and policy‚Ä¶\n\n\n\nNam Vien\n\n\nMay 10, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "About.html",
    "href": "About.html",
    "title": "About",
    "section": "",
    "text": "Nam Vien\nYes\nNo\nNegotiable\n\n\n\n\nU.S. Citizen\n‚úì\n\n\n\n\nAuthorized to work in the U.S.\n‚úì\n\n\n\n\nRelocation for work\n\n\n‚úì\n\n\nWilling to travel for work\n‚úì\n\n\n\n\nOn-site/Hybrid/Remote\n‚úì\n\n\n\n\nFull-time/Part-time\n‚úì\n\n\n\n\nInternship/Research Opportunity\n‚úì\n\n\n\n\nFelony or misdemeanor\n\n‚úó\n\n\n\n\n\nBackground\n\nProgramming languages proficiency: Python and R.\nFluent in Vietnamese and Cantonese, in addition to English.\n\n\n\nProfessional Relevance\n\nAcademic and Career Focus:\n\nPassionate about leveraging AI/ML to solve real-world challenges through innovative, data-driven, and applicable solutions.\n\nTrained in Statistics and Data Science at UCLA with a Minor in Digital Humanities, combining technical expertise with an interest in addressing business and social issues through data.\n\n\n\n\nKey Projects and Experiences\n\nSaciva: Enhancing International Student Support\n\nOverview: Designed and implemented a university clustering model using geographic proximity data to assist over 1 million international students annually.\nClustering Approach: Used advanced algorithms like DBSCAN to group universities based on commute distances, creating intuitive, location-based networks for housing and roommate matching.\nProfiles and Insights: Enhanced user experience by providing region-specific profiles that include cost of living, climate, and safety metrics, empowering students to make informed decisions.\nImpact: Replaced manual filtering with cluster-based recommendations, reducing decision fatigue and increasing resource accessibility.\n\n\n\n\nValues\n\nCommit to celebrating and promoting cultural diversity and inclusion, as demonstrated through my work with Saciva and the Data Justice Scholars program.\n\nEngage in efforts to uplift underserved communities, including people of color, immigrants, foster youth, LGBTQ+, and low-income families.\n\nStrive to create innovative, data-driven, and applicable solutions that address social inequities and empower everyone to achieve greater opportunities and success together.\n\n\n\nLet‚Äôs Connect!\nFeel free to reach out to me on LinkedIn or explore my projects on GitHub.\nI am always open to discussing innovative ideas, collaborations, or career opportunities!"
  },
  {
    "objectID": "Project 6.html",
    "href": "Project 6.html",
    "title": "Project 6 - Surveillance & Equity",
    "section": "",
    "text": "The Racial Diversity & the Use of Facial Recognition Technology project, developed as part of a digital mapping initiative, investigates the spatial distribution of facial recognition technology (FRT) in U.S. cities and its implications for racially diverse populations. By combining demographic data, policy research, and geospatial analysis, the project examines how surveillance technologies may exacerbate existing inequalities and civil liberties concerns.\n\nTools and Methodologies Used\nThe project integrated several digital humanities and geospatial tools to investigate the social consequences of surveillance:\n\nData Collection and Analysis:\n\nCensus Data: Provided demographic information on racial and ethnic composition at the neighborhood level.\nPolicy Reports: Synthesized local and national FRT policies, bans, and advocacy responses.\nArcGIS: Used to analyze spatial patterns and overlay racial diversity with locations of FRT deployment.\n\nMapping and Visualization:\n\nArcGIS StoryMaps: Served as the primary platform for digital storytelling, combining narrative text with interactive maps and infographics.\nData Dashboards: Embedded visualizations helped illustrate disparities and raise questions about surveillance targeting.\n\nWeb Development and Design:\n\nCustom Interface Elements: Timeline, callout boxes, and map pop-ups guided users through key findings and critical perspectives.\n\nCollaboration:\n\nShared Editorial Review: Students worked collectively to refine narratives, visual clarity, and citation accuracy.\nPeer Feedback: Iterative review processes helped sharpen arguments and improve accessibility.\n\n\n\n\nMeasurable Outcomes\nThe project produced meaningful insights and outcomes:\n\nGeospatial Insight: Revealed a correlation between FRT presence and areas with higher racial diversity, suggesting disproportionate surveillance in marginalized communities.\nPublic Engagement: The interactive format increased accessibility and engagement, reaching educators, policymakers, and advocacy groups interested in digital justice.\nPolicy Awareness: Provided a synthesized overview of cities with active FRT bans or proposals, encouraging informed civic participation.\n\n\n\nQuestions This Project Can Answer\nThe project offers a framework to explore and debate complex surveillance issues:\n\nEquity and Surveillance: Are racially diverse communities more likely to be monitored by facial recognition systems?\nTechnology and Policy: How do local governments regulate or resist the adoption of facial recognition?\nSocial Justice Implications: What role does public data play in making visible patterns of bias in technological infrastructure?\nDigital Ethics: How can urban surveillance be designed or limited to avoid civil rights violations?\n\n\n\nPersonal Learning and Skill Development\nThis project contributed to both academic and technical growth:\n\nCritical Data Interpretation: Learned to contextualize quantitative data within broader social and ethical frameworks.\nGeospatial Literacy: Gained experience using ArcGIS StoryMaps to visualize spatial injustice and drive narrative impact.\nCivic Technology Awareness: Developed an understanding of how digital tools intersect with real-world policy debates and advocacy.\nEthical Communication: Practiced translating complex technological debates into accessible formats for diverse audiences.\n\n\n\n\nThis project was part of Professor Wendy Kurtz‚Äôs DH178 Capstone Seminar: (Re)Defining LA S25 at UCLA Digital Humanities Department."
  },
  {
    "objectID": "projects/Project 6/Project 6.html",
    "href": "projects/Project 6/Project 6.html",
    "title": "Project 6 - Surveillance & Equity",
    "section": "",
    "text": "The Racial Diversity & the Use of Facial Recognition Technology project, developed as part of a digital mapping initiative, investigates the spatial distribution of facial recognition technology (FRT) in U.S. cities and its implications for racially diverse populations. By combining demographic data, policy research, and geospatial analysis, the project examines how surveillance technologies may exacerbate existing inequalities and civil liberties concerns.\n\nTools and Methodologies Used\nThe project integrated several digital humanities and geospatial tools to investigate the social consequences of surveillance:\n\nData Collection and Analysis:\n\nCensus Data: Provided demographic information on racial and ethnic composition at the neighborhood level.\nPolicy Reports: Synthesized local and national FRT policies, bans, and advocacy responses.\nArcGIS: Used to analyze spatial patterns and overlay racial diversity with locations of FRT deployment.\n\nMapping and Visualization:\n\nArcGIS StoryMaps: Served as the primary platform for digital storytelling, combining narrative text with interactive maps and infographics.\nData Dashboards: Embedded visualizations helped illustrate disparities and raise questions about surveillance targeting.\n\nWeb Development and Design:\n\nCustom Interface Elements: Timeline, callout boxes, and map pop-ups guided users through key findings and critical perspectives.\n\nCollaboration:\n\nShared Editorial Review: Students worked collectively to refine narratives, visual clarity, and citation accuracy.\nPeer Feedback: Iterative review processes helped sharpen arguments and improve accessibility.\n\n\n\n\nMeasurable Outcomes\nThe project produced meaningful insights and outcomes:\n\nGeospatial Insight: Revealed a correlation between FRT presence and areas with higher racial diversity, suggesting disproportionate surveillance in marginalized communities.\nPublic Engagement: The interactive format increased accessibility and engagement, reaching educators, policymakers, and advocacy groups interested in digital justice.\nPolicy Awareness: Provided a synthesized overview of cities with active FRT bans or proposals, encouraging informed civic participation.\n\n\n\nQuestions This Project Can Answer\nThe project offers a framework to explore and debate complex surveillance issues:\n\nEquity and Surveillance: Are racially diverse communities more likely to be monitored by facial recognition systems?\nTechnology and Policy: How do local governments regulate or resist the adoption of facial recognition?\nSocial Justice Implications: What role does public data play in making visible patterns of bias in technological infrastructure?\nDigital Ethics: How can urban surveillance be designed or limited to avoid civil rights violations?\n\n\n\nPersonal Learning and Skill Development\nThis project contributed to both academic and technical growth:\n\nCritical Data Interpretation: Learned to contextualize quantitative data within broader social and ethical frameworks.\nGeospatial Literacy: Gained experience using ArcGIS StoryMaps to visualize spatial injustice and drive narrative impact.\nCivic Technology Awareness: Developed an understanding of how digital tools intersect with real-world policy debates and advocacy.\nEthical Communication: Practiced translating complex technological debates into accessible formats for diverse audiences.\n\n\n\n\nThis project was part of Professor Wendy Kurtz‚Äôs DH 131 - Digital Mapping and Critical Geographic Information Systems\nat UCLA Digital Humanities Department."
  },
  {
    "objectID": "Portfolio.html",
    "href": "Portfolio.html",
    "title": "Portfolio",
    "section": "",
    "text": "I build clarity from complexity.\nAcross my projects, I focus on understanding users, synthesizing insights, defining problems, and creating scalable systems that enable intuitive experiences, especially for social, creator-driven, and community-centered products.\nThis portfolio highlights how I translate ambiguous challenges into structured, data-informed strategies and early product concepts."
  },
  {
    "objectID": "Portfolio.html#designing-user-ecosystem-segmentation-to-improve-discovery-community-formation",
    "href": "Portfolio.html#designing-user-ecosystem-segmentation-to-improve-discovery-community-formation",
    "title": "Portfolio",
    "section": "Designing User Ecosystem Segmentation to Improve Discovery & Community Formation",
    "text": "Designing User Ecosystem Segmentation to Improve Discovery & Community Formation\nRole: AI Studio Fellow (Aug‚ÄìDec 2024)\nDomain: Social discovery ‚Ä¢ onboarding flows ‚Ä¢ segmentation ‚Ä¢ user insights ‚Ä¢ operational alignment"
  },
  {
    "objectID": "Portfolio.html#overview",
    "href": "Portfolio.html#overview",
    "title": "Portfolio",
    "section": "1. Overview",
    "text": "1. Overview\nInternational students navigating the U.S. face fragmented information, unclear local differences, and difficulty building social ties.\nSaciva aims to reduce this friction by helping 1M+ international students discover communities, locations, and resources that match their needs.\nMy work focused on understanding user ecosystems and developing a segmentation framework that supports more personalized and intuitive discovery experiences."
  },
  {
    "objectID": "Portfolio.html#problem",
    "href": "Portfolio.html#problem",
    "title": "Portfolio",
    "section": "2. Problem",
    "text": "2. Problem\nStudents often cannot answer essential questions:\n\nWhere can I find safe, affordable housing?\n\nWhat areas feel similar to my home environment?\n\nWhere are people like me?\n\nWhich regions match my lifestyle and needs?\n\nFilters alone cannot answer these ‚Äî they lack context, proximity awareness, and environmental nuance.\nSaciva needed a user-centered, data-driven foundation for recommendations and onboarding flows."
  },
  {
    "objectID": "Portfolio.html#goal",
    "href": "Portfolio.html#goal",
    "title": "Portfolio",
    "section": "3. Goal",
    "text": "3. Goal\nCreate an ecosystem model that:\n\nGroups environments in ways students actually perceive them\n\nSupports personalized discovery (like TikTok‚Äôs For You Page, but for regions)\n\nReduces cognitive load in relocation decisions\n\nHelps product teams understand user needs at scale\n\nThis mirrors core PM responsibilities:\nproblem definition ‚Üí insight generation ‚Üí modeling ‚Üí prototyping"
  },
  {
    "objectID": "Portfolio.html#my-role",
    "href": "Portfolio.html#my-role",
    "title": "Portfolio",
    "section": "4. My Role",
    "text": "4. My Role\nI led analytical and product-thinking contributions across:\n\nUser needs exploration\n\nInsight synthesis across multi-source datasets\n\nEvaluation of clustering methods for user-relevant grouping\n\nEarly prototype development (interactive cluster maps)\n\nCommunicating findings to the CEO and team for product direction"
  },
  {
    "objectID": "Portfolio.html#process",
    "href": "Portfolio.html#process",
    "title": "Portfolio",
    "section": "5. Process",
    "text": "5. Process\n\nüîç a. User & Environment Research\nSynthesized patterns across:\n\nUniversity locations\n\nClimate\n\nCrime/safety\n\nCost of living\n\nIncome demographics\n\nGuiding product question:\nHow do these factors shape where students want to live and who they want to connect with?\n\n\n\nüß© b. Segmentation Strategy for Discovery Flows\nEvaluated three clustering approaches:\n\nDBSCAN\n\nMean Shift\n\nAgglomerative clustering\n\nDBSCAN emerged as the strongest performer (silhouette score: 0.868), producing 294 meaningful regional clusters.\nWhy PMs care:\nThis segmentation created a foundation for:\n\nBetter onboarding (‚ÄúWhat areas match your profile?‚Äù)\n\nPersonalized recommendations\n\nLocalized content relevance\n\nOperational planning for community tools\n\n\n\n\nüó∫Ô∏è c.¬†Prototype: Interactive Ecosystem Map\nBuilt a Folium-based map visualizing:\n\n294 environmental segments\n\nAffordability\n\nClimate similarity\n\nSafety patterns\n\nRegional profiles\n\nThis tool improved stakeholder understanding and enabled faster product ideation for student discovery flows."
  },
  {
    "objectID": "Portfolio.html#outcome",
    "href": "Portfolio.html#outcome",
    "title": "Portfolio",
    "section": "6. Outcome",
    "text": "6. Outcome\n\nGenerated insights that shaped early product direction for onboarding and discovery\n\nDeveloped a segmentation model applicable to community-building, recommendations, and localized user experiences\n\nDelivered a prototype that improved stakeholder clarity on user ecosystems\n\nHelped define strategic opportunities for student engagement"
  },
  {
    "objectID": "Portfolio.html#relevance-to-tiktok-pm-creator-ops",
    "href": "Portfolio.html#relevance-to-tiktok-pm-creator-ops",
    "title": "Portfolio",
    "section": "7. Relevance to TikTok PM & Creator Ops",
    "text": "7. Relevance to TikTok PM & Creator Ops\n\nüéØ For Product Management:\n\nUser needs framing\n\nProblem-first thinking\n\nData-informed product reasoning\n\nPrototyping to explore feasibility\n\nCommunicating insights to influence strategy\n\n\n\nüé® For Creator Operations:\n\nAudience segmentation\n\nInsight generation for content relevance\n\nOperational visibility into local ecosystems\n\nCross-functional alignment with leadership"
  },
  {
    "objectID": "Portfolio.html#welcome",
    "href": "Portfolio.html#welcome",
    "title": "Portfolio",
    "section": "",
    "text": "I build clarity from complexity.\nAcross my projects, I focus on understanding users, synthesizing insights, defining problems, and creating scalable systems that enable intuitive experiences ‚Äî especially for social, creator-driven, and community-centered products.\nThis portfolio highlights how I translate ambiguous challenges into structured, data-informed strategies and early product concepts."
  },
  {
    "objectID": "Portfolio.html#case-study-saciva",
    "href": "Portfolio.html#case-study-saciva",
    "title": "Portfolio",
    "section": "üß≠ Case Study: Saciva",
    "text": "üß≠ Case Study: Saciva\n\nDesigning User Ecosystem Segmentation to Improve Discovery and Community Formation\nRole: AI Studio Fellow\nDomain: Social discovery ‚Ä¢ onboarding flows ‚Ä¢ segmentation ‚Ä¢ user insights ‚Ä¢ operational alignment\n\n\n1. Overview\nInternational students navigating the U.S. face fragmented information, unclear local differences, and difficulty building social ties.\nSaciva aims to reduce this friction by helping over one millions international students in the U.S. discover communities, locations, and resources that match their needs.\nMy work focused on understanding user ecosystems and developing a segmentation framework that supports more personalized and intuitive discovery experiences.\n\n\n2. Problem\nStudents often cannot answer essential questions:\n\nWhere can I find safe, affordable housing?\n\nWhat areas feel similar to my home environment?\n\nWhere are people like me?\n\nWhich regions match my lifestyle and needs?\n\nFilters alone cannot answer these ‚Äî they lack context, proximity awareness, and environmental nuance.\nSaciva needed a user-centered, data-driven foundation for recommendations and onboarding flows.\n\n\n3. Goal\nCreate an ecosystem model that:\n\nGroups environments in ways students actually perceive them\n\nSupports personalized discovery\nReduces cognitive load in relocation decisions\n\nHelps product teams understand user needs at scale\n\n\n\n4. My Role\nI led analytical and product-thinking contributions across:\n\nUser needs exploration\n\nInsight synthesis across multi-source datasets\n\nEvaluation of clustering methods for user-relevant grouping\n\nEarly prototype development (interactive cluster maps)\n\nExchanging findings to the CEO and team for product direction\n\n\n\n5. Process\n\nüîç a. User & Environment Research\nSynthesized patterns across:\n\nUniversity locations\n\nClimate\n\nCrime/safety\n\nCost of living\n\nIncome demographics\n\nGuiding product question:\nHow do these factors shape where students want to live and who they want to connect with?\n\n\nüß© b. Segmentation Strategy for Discovery Flows\n\n\n\n\n\n\n\nClustering Method\nClustering Approaches Evaluation\n\n\n\n\nDBSCAN1\nGeographic Insights:DBSCAN reveals high-density student pockets, creating many small but meaningful regional clusters:‚Ä¢ West Coast microclusters (Seattle, Bay Area, SoCal) ‚Ä¢ Mountain West pockets (Utah, Colorado) ‚Ä¢ Midwest city groups (Chicago, Minneapolis) ‚Ä¢ Northeast metro chain (Boston ‚Üí NYC ‚Üí Philly ‚Üí DC) ‚Ä¢ Southern hubs (Atlanta, DFW, Houston, Miami) ‚Ä¢ Florida as a distinct region ‚Ä¢ Gray points = low-density/noise points \n\n\nMean Shift2\nGeographic Insights:Mean Shift identifies regional density peaks, producing smooth and coherent geographic groupings:‚Ä¢ PNW + Northern California shared corridor ‚Ä¢ Southern California as its own region ‚Ä¢ Southwest corridor (AZ, NM, TX) ‚Ä¢ Midwest cluster (IL, WI, MN) ‚Ä¢ East Coast subclusters: New England, Mid-Atlantic, Southeast ‚Ä¢ Florida as a compact cluster \n\n\nAgglomerative Clustering3\nGeographic Insights:Agglomerative produces clean, contiguous macro-regions, revealing structured geographic boundaries:‚Ä¢ Pacific Northwest, Northern California, Southern California as distinct segments ‚Ä¢ Unified Southwest region (AZ, NM, West TX) ‚Ä¢ Central U.S. + Texas region ‚Ä¢ Upper Midwest (MN, WI, MI) ‚Ä¢ Mid-Atlantic and New England as stable clusters ‚Ä¢ Southeast region (Carolinas + Georgia) ‚Ä¢ Florida as isolated region \n\n\n\nAccording to the findings, DBSCAN emerged as the strongest performer (silhouette score4: 0.868), producing 294 meaningful regional clusters.\nThis segmentation created a foundation for:\n\nBetter onboarding (‚ÄúWhat areas match your profile?‚Äù)\n\nPersonalized recommendations\n\nLocalized content relevance\n\nOperational planning for community tools\n\n\n\nüó∫Ô∏è c.¬†Prototype: Interactive Ecosystem Map\nBuilt a Folium-based map visualizing:\n\n294 environmental segments\n\nAffordability\n\nClimate similarity\n\nSafety patterns\n\nRegional profiles\n\nThis tool improved stakeholder understanding and enabled faster product ideation for student discovery flows.\n\n\n\n6. Outcome\n\nGenerated insights that shaped early product direction for onboarding and discovery\n\nDeveloped a segmentation model applicable to community-building, recommendations, and localized user experiences\n\nDelivered a prototype that improved stakeholder clarity on user ecosystems\n\nHelped define strategic opportunities for student engagement\n\n\n\n7. Alignment with TikTok‚Äôs Mission & Product Vision\n\nTransformed fragmented student challenges into structured insights by identifying patterns in safety, affordability, climate, and community factors, supporting TikTok‚Äôs vision of creating intuitive, accessible experiences rooted in real user needs.\nEvaluated and selected DBSCAN as the most meaningful segmentation approach through data-driven reasoning, contributing to the type of scalable understanding of user ecosystems that underpins TikTok‚Äôs personalized discovery and community-building features.\nDeveloped an interactive ecosystem prototype that clarified how users navigate their environments and form connections, reflecting TikTok‚Äôs commitment to empowering people with tools that help them explore, discover, and build meaningful relationships."
  },
  {
    "objectID": "Portfolio.html#hi-welcome",
    "href": "Portfolio.html#hi-welcome",
    "title": "Portfolio",
    "section": "",
    "text": "I build clarity from complexity.\nAcross my projects, I focus on understanding users, synthesizing insights, defining problems, and creating scalable systems that enable intuitive experiences, especially for social, creator-driven, and community-centered products.\nThis portfolio highlights how I translate ambiguous challenges into structured, data-informed strategies and early product concepts."
  },
  {
    "objectID": "Untitled.html",
    "href": "Untitled.html",
    "title": "Tooltip Test",
    "section": "",
    "text": "Here is a simple tooltip using plain HTML:\nHover over this text\nAnd here is a tooltip with custom styling:\n\nHere is DBSCAN with a custom tooltip:\nDBSCAN"
  },
  {
    "objectID": "Portfolio.html#footnotes",
    "href": "Portfolio.html#footnotes",
    "title": "Portfolio",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nA density-based clustering algorithm that groups nearby points without needing a preset number of clusters.‚Ü©Ô∏é\nA clustering method that moves data points toward high-density regions to automatically discover cluster centers.‚Ü©Ô∏é\nA hierarchical method that merges the closest clusters step-by-step to form structured regional groups.‚Ü©Ô∏é\nA silhouette score measures how well each data point fits within its assigned cluster, with higher values indicating clearer and more separated groupings.‚Ü©Ô∏é"
  },
  {
    "objectID": "projects/Project 1/Graphs.html",
    "href": "projects/Project 1/Graphs.html",
    "title": "Nam Vien",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import DBSCAN, MeanShift, AgglomerativeClustering, estimate_bandwidth\n\n# Load data\nlatlon = pd.read_csv('/content/latitude_longitude_with_clusters.csv')\nX = latlon[['LATITUDE','LONGITUDE']].values\n\n# Filter US bounds\nmask = (X[:,0] &gt; 15) & (X[:,0] &lt; 55) & (X[:,1] &gt; -130) & (X[:,1] &lt; -60)\nX_filtered = X[mask]\n\n# Sample for performance\nnp.random.seed(42)\nsample_idx = np.random.choice(len(X_filtered), size=min(3000, len(X_filtered)), replace=False)\nX_sample = X_filtered[sample_idx]\n\n#################################\n# 1. DBSCAN\n#################################\ndb = DBSCAN(eps=0.3, min_samples=5).fit(X_sample)\ndb_labels = db.labels_\n\nunique_labels = sorted(set(db_labels))\ncmap = plt.cm.tab20\ncolors = [cmap(i % 20) for i in range(len(unique_labels))]\ncolor_map = {lbl: (0.8,0.8,0.8,1) if lbl == -1 else colors[i] for i, lbl in enumerate(unique_labels)}\ndb_colors = [color_map[lbl] for lbl in db_labels]\n\nplt.figure(figsize=(9,7))\nplt.scatter(X_sample[:,1], X_sample[:,0], c=db_colors, s=10)\nplt.title(\"DBSCAN\", fontsize=18)\nplt.xlabel(\"Longitude\")\nplt.ylabel(\"Latitude\")\nplt.grid(True, linestyle='--', alpha=0.4)\nplt.tight_layout()\ndb_path = \"/content/DBSCAN.png\"\nplt.savefig(db_path, dpi=300)\nplt.close()\n\n#################################\n# 2. Mean Shift\n#################################\nbandwidth = estimate_bandwidth(X_sample, quantile=0.2)\nreduced_bw = bandwidth * 0.4\nms = MeanShift(bandwidth=reduced_bw, bin_seeding=True).fit(X_sample)\nms_labels = ms.labels_\n\nunique_labels = sorted(set(ms_labels))\ncolors = [cmap(i % 20) for i in range(len(unique_labels))]\ncolor_map = {lbl: colors[i] for i, lbl in enumerate(unique_labels)}\nms_colors = [color_map[lbl] for lbl in ms_labels]\n\nplt.figure(figsize=(9,7))\nplt.scatter(X_sample[:,1], X_sample[:,0], c=ms_colors, s=10)\nplt.title(\"Mean Shift\", fontsize=18)\nplt.xlabel(\"Longitude\")\nplt.ylabel(\"Latitude\")\nplt.grid(True, linestyle='--', alpha=0.4)\nplt.tight_layout()\nms_path = \"/content/MeanShift.png\"\nplt.savefig(ms_path, dpi=300)\nplt.close()\n\n#################################\n# 3. Agglomerative Clustering\n#################################\nagg = AgglomerativeClustering(n_clusters=10).fit(X_sample)\nagg_labels = agg.labels_\n\nunique_labels = sorted(set(agg_labels))\ncolors = [cmap(i % 20) for i in range(len(unique_labels))]\ncolor_map = {lbl: colors[i] for i, lbl in enumerate(unique_labels)}\nagg_colors = [color_map[lbl] for lbl in agg_labels]\n\nplt.figure(figsize=(9,7))\nplt.scatter(X_sample[:,1], X_sample[:,0], c=agg_colors, s=10)\nplt.title(\"Agglomerative Clustering\", fontsize=18)\nplt.xlabel(\"Longitude\")\nplt.ylabel(\"Latitude\")\nplt.grid(True, linestyle='--', alpha=0.4)\nplt.tight_layout()\nagg_path = \"/content/Agglomerative.png\"\nplt.savefig(agg_path, dpi=300)\nplt.close()\n\nimport matplotlib.image as mpimg\n\nfor path, title in [(db_path, \"DBSCAN\"), (ms_path, \"Mean Shift\"), (agg_path, \"Agglomerative Clustering\")]:\n    img = mpimg.imread(path)\n    plt.figure(figsize=(8,6))\n    plt.imshow(img)\n    plt.axis('off')\n    plt.show()"
  }
]